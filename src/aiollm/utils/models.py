import datetime

from aiollm.models.model import Model, ModelFeatures, ModelPrice

MODEL_NAMES = {
    "openai:gpt-4o-mini": Model(
        id="gpt-4o-mini",
        name="GPT-4o mini",
        provider="OpenAI",
        max_context_tokens=128_000,
        max_completion_tokens=16_384,
        knowledge_cutoff=datetime.date(2023, 10, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=False,
        ),
        price=ModelPrice(
            input=0.15 / 1_000_000,
            output=0.6 / 1_000_000,
        ),
    ),
    "openai:gpt-4o": Model(
        id="gpt-4o-2024-08-06",
        name="GPT-4o",
        provider="OpenAI",
        max_context_tokens=128_000,
        max_completion_tokens=16_384,
        knowledge_cutoff=datetime.date(2023, 10, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=False,
        ),
        price=ModelPrice(
            input=2.50 / 1_000_000,
            cached_input=1.25 / 1_000_000,
            output=10.00 / 1_000_000,
        ),
    ),
    "openai:gpt-4.1-nano": Model(
        id="gpt-4.1-nano-2025-04-14",
        name="GPT-4.1 nano",
        provider="OpenAI",
        max_context_tokens=1_047_576,
        max_completion_tokens=32_768,
        knowledge_cutoff=datetime.date(2024, 6, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=False,
        ),
        price=ModelPrice(
            input=0.1 / 1_000_000,
            cached_input=0.025 / 1_000_000,
            output=0.4 / 1_000_000,
        ),
    ),
    "openai:gpt-4.1-mini": Model(
        id="gpt-4.1-mini-2025-04-14",
        name="GPT-4.1 mini",
        provider="OpenAI",
        max_context_tokens=1_047_576,
        max_completion_tokens=32_768,
        knowledge_cutoff=datetime.date(2024, 6, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=False,
        ),
        price=ModelPrice(
            input=0.4 / 1_000_000,
            cached_input=0.1 / 1_000_000,
            output=1.6 / 1_000_000,
        ),
    ),
    "openai:gpt-4.1": Model(
        id="gpt-4.1-2025-04-14",
        name="GPT-4.1",
        provider="OpenAI",
        max_context_tokens=1_047_576,
        max_completion_tokens=32_768,
        knowledge_cutoff=datetime.date(2024, 6, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=False,
        ),
        price=ModelPrice(
            input=2.0 / 1_000_000,
            cached_input=0.5 / 1_000_000,
            output=8.0 / 1_000_000,
        ),
    ),
    "openai:o1": Model(
        id="o1-2024-12-17",
        name="o1",
        provider="OpenAI",
        max_context_tokens=200_000,
        max_completion_tokens=100_000,
        knowledge_cutoff=datetime.date(2023, 10, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=True,
        ),
        price=ModelPrice(
            input=15.0 / 1_000_000,
            cached_input=7.5 / 1_000_000,
            output=60.0 / 1_000_000,
        ),
    ),
    "openai:o1-pro": Model(
        id="o1-pro-2025-03-19",
        name="o1 pro",
        provider="OpenAI",
        max_context_tokens=200_000,
        max_completion_tokens=100_000,
        knowledge_cutoff=datetime.date(2023, 10, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=True,
        ),
        price=ModelPrice(
            input=150.0 / 1_000_000,
            output=600.0 / 1_000_000,
        ),
    ),
    "openai:o3-mini": Model(
        id="o3-mini-2025-01-31",
        name="o3 mini",
        provider="OpenAI",
        max_context_tokens=200_000,
        max_completion_tokens=100_000,
        knowledge_cutoff=datetime.date(2023, 10, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=False,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=True,
        ),
        price=ModelPrice(
            input=1.0 / 1_000_000,
            cached_input=0.55 / 1_000_000,
            output=4.4 / 1_000_000,
        ),
    ),
    "openai:o3": Model(
        id="o3-2025-04-16",
        name="o3",
        provider="OpenAI",
        max_context_tokens=200_000,
        max_completion_tokens=100_000,
        knowledge_cutoff=datetime.date(2024, 6, 1),
        features=ModelFeatures(
            text_input=True,
            image_input=True,
            text_output=True,
            image_output=False,
            streaming=True,
            function_calling=True,
            structured_output=True,
            reasoning=True,
        ),
        price=ModelPrice(
            input=1.0 / 1_000_000,
            cached_input=0.55 / 1_000_000,
            output=4.4 / 1_000_000,
        ),
    ),
}


def load_model_by_name(namespace: str) -> Model:
    if namespace in MODEL_NAMES:
        return MODEL_NAMES[namespace]

    provider_name, model_id = namespace.split(":", 1)
    return Model(id=model_id, name=model_id, provider=provider_name)
